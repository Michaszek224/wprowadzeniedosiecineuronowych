{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Wprowadzenie do sieci neuronowych i uczenia maszynowego\n",
        "## Lab: Podstawowe moduły sieci neuronowych w PyTorch\n",
        "\n",
        "---\n",
        "\n",
        "**Autorzy materiałów:** Piotr Baryczkowski, Jakub Bednarek<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji.\n"
      ],
      "metadata": {
        "id": "o8aSyboqZ40M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "\n",
        "* zapoznanie się z pojęciem **zbioru danych** i jego charakterystyką,\n",
        "* wykorzystanie podstawowych warstw neuronowych,\n",
        "* implementacja procesu uczenia sieci neuronowej + *good practices*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8ToIOrDr7A8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s10XO61Fn57k"
      },
      "source": [
        "## Zbiór danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNwfaIiuy6ar"
      },
      "source": [
        "### Wprowadzenie oraz popularne zbiory danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzwK1KIvl_t"
      },
      "source": [
        "Odpowiednie przygotowanie zbioru danych odgrywa znaczącą rolę w uczeniu sieci neuronowych. Zazwyczaj zbiory danych zawierają 3 pozbiory:\n",
        "\n",
        "* treningowy - wykorzystywany do uaktualniania wag modelu neuronowego,\n",
        "* walidacyjny - do oceny modelu po każdej **epoce**,\n",
        "* testowy - do porównania modelu z innymi rozwiązaniami.\n",
        "\n",
        "**Uwaga:** bardzo często popularne zbiory danych nie posiadają zbioru testowego, ponieważ nie prowadzą tzw. **leaderboard**.\n",
        "\n",
        "Najpopularniejsze zbiory danych:\n",
        "\n",
        "* **MNIST**,\n",
        "* eMNIST,\n",
        "* Caltech 101/256,\n",
        "* Cityscapes,\n",
        "* Kitty,\n",
        "* LFW Face Dataset,\n",
        "* ImageNet\n",
        "\n",
        "Więcej informacji: [wiki](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research) [kaggle](https://www.kaggle.com/datasets) [google](https://toolbox.google.com/datasetsearch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWwP2RtTy-9o"
      },
      "source": [
        "### Obsługa zbioru danych w PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29POyzqin9L1"
      },
      "source": [
        "Kod do przetwarzania danych może stać się nieczytelny i trudny do utrzymania; idealnie chcielibyśmy, aby kod związany z naszym zestawem danych był oddzielony od kodu, który odpowiada za uczenie modelu. PyTorch udostępnia dwie klasy do obsługi danych: `torch.utils.data.DataLoader` i `torch.utils.data.Dataset`, które pozwalają na użycie zarówno gotowych zestawów danych, jak i własnych. `Dataset` przechowuje próbki i ich odpowiadające etykiety, a `DataLoader` jest swego rodzaju nakładką na obiekt `Dataset`, umożliwiając łatwy dostęp do próbek - ładowanie danych, dzielenie danych na podzbiory (_ang. batch_). [link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDh89pFDzGca"
      },
      "source": [
        "#### Tworzenie zbioru danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S59kIwgz5x1"
      },
      "outputs": [],
      "source": [
        "dataset_size = 10\n",
        "\n",
        "# zbiór danych składający się z losowych obrazków o rozmiarze (32, 32, 3) oraz etykiet po kolei od 0 do dataset_size\n",
        "x = [np.random.uniform(size=(32, 32, 3)) for _ in range(dataset_size)]\n",
        "y = [i for i in range(dataset_size)]\n",
        "\n",
        "tensor_x = torch.Tensor(x)\n",
        "tensor_y = torch.Tensor(y)\n",
        "\n",
        "# utworzenie \"iteratora\" zbioru danych\n",
        "dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
        "dataloader = torch.utils.data.DataLoader(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latEGDXR1BDT"
      },
      "source": [
        "#### Iterowanie po zbiorze danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJZo9pGz1EX8"
      },
      "outputs": [],
      "source": [
        "for x, y in dataloader:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8xxrDkx1b_r"
      },
      "source": [
        "#### Tasowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzQhivcx1wjY"
      },
      "outputs": [],
      "source": [
        "dataloader_shuffled = torch.utils.data.DataLoader(dataset, shuffle=True)\n",
        "\n",
        "for x, y in dataloader_shuffled:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUFB46tu15qP"
      },
      "source": [
        "#### Mapowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxLq1Jwa17HN"
      },
      "outputs": [],
      "source": [
        "class MappedDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, transform_func):\n",
        "    self.dataset = dataset\n",
        "    self.transform_func = transform_func\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data, label = self.dataset[idx]\n",
        "    return self.transform_func(data, label)\n",
        "\n",
        "\n",
        "def map(x, y):\n",
        "  y = y * 2\n",
        "  return x, y\n",
        "\n",
        "\n",
        "dataset_mapped = MappedDataset(dataset, map)\n",
        "dataloader_mapped = torch.utils.data.DataLoader(dataset_mapped)\n",
        "\n",
        "for x, y in dataloader_mapped:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TUb4toF2T-8"
      },
      "source": [
        "#### Filtrowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZOTi5mz2Vpf"
      },
      "outputs": [],
      "source": [
        "class FilteredDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, threshold):\n",
        "    self.filtered_data = [\n",
        "      (data, label) for data, label in dataset if label > threshold\n",
        "    ]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filtered_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.filtered_data[idx]\n",
        "\n",
        "\n",
        "dataset_filtered = FilteredDataset(dataset, 5)\n",
        "\n",
        "dataloader_filtered = torch.utils.data.DataLoader(dataset_filtered)\n",
        "\n",
        "for x, y in dataloader_filtered:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhZmXSZJ2fc3"
      },
      "source": [
        "#### Grupowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLaNPS6A2iK5"
      },
      "outputs": [],
      "source": [
        "dataloader_batch = torch.utils.data.DataLoader(dataset, batch_size=5)\n",
        "\n",
        "for x, y in dataloader_batch:\n",
        "  print(x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_98O2Zsr2xEP"
      },
      "source": [
        "#### Składanie wielu operacji na raz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2o3BqWb2z27"
      },
      "outputs": [],
      "source": [
        "dataset_mix = MappedDataset(dataset, map)\n",
        "dataset_mix = FilteredDataset(dataset_mix, 6)\n",
        "\n",
        "dataloader_mix = torch.utils.data.DataLoader(dataset_mix, shuffle=True, batch_size=5)\n",
        "\n",
        "for x, y in dataloader_mix:\n",
        "  print(x[0, 0, 0, 0], x.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2s7Isp4633N"
      },
      "source": [
        "#### Zadanie 1\n",
        "\n",
        "Stwórz zbiór danych (bez podziału na zbiory treningowe, walidacyjne i testowy) składający się z 10000 elementów, zawierający pary (x, y) danych\n",
        "dla funkcji **sinus**. Dane x niech będą z zakresu [-2 * PI, 2 * PI], y - odpowiadające im wartości funkcji sinus.\n",
        "\n",
        "Następnie utwórz providera za pomocą PyTorch Dataset API, który będzie:\n",
        "\n",
        "* tasował dane\n",
        "* mapował tak, aby dane x, z zakresu [-2 \\* PI, 0), były transformowane do przedziału [0, 2 \\* PI)\n",
        "\n",
        "Podpowiedź: (x + 2PI) % 2PI,\n",
        "* grupował dane w batche o rozmiarze 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1hnkzMEA7l_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "dataset_size = 10000\n",
        "\n",
        "x = ...\n",
        "y = ...\n",
        "\n",
        "def transform_sinus(x, y):\n",
        "  return ...\n",
        "\n",
        "dataset = ...\n",
        "mappedDataset = ...\n",
        "dataloader = ...\n",
        "\n",
        "for x, y in dataloader:\n",
        "  print(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TJaDyXCA9Qe"
      },
      "source": [
        "### Popularne zbiory danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp29iNwaBBhw"
      },
      "source": [
        "Biblioteka PyTorch zawiera gotowe funkcje wczytujące dla niektórych zbiorów danych. Większość gotowych zbiorów danych możemy znaleźć w bibliotece *torchvision*. Tutaj możesz znaleźć dokładną listę dostępnych zbiorów danych - [link](https://pytorch.org/vision/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQp1MMjzB9Di"
      },
      "source": [
        "Jednym z popularniejszych zbiorów danych jest MNIST. Jest to zbiór zawierający cyfry pochodzące z pisma odręcznego wraz z ich przypisanymi etykietami ('1', '2', etc.). Poniżej przykładowe pobranie i wykorzystanie zbioru MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcggguYcB-8U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJEqdWYeHhg-"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4PMPG23oKgP"
      },
      "source": [
        "## Podstawowe warstwy neuronowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um8QcBw-qE3a"
      },
      "source": [
        "Przy projektowaniu sieci neuronowych możemy wyróżnić podstawowe operacje (warstwy), które się powtarzają. Dla wygody, PyTorch zawiera gotowe implementacje najprostszych z nich, oraz udostępnia interfejsy do tworzenia własnych, bardziej skomplikowanych.\n",
        "\n",
        "Operacje możemy podzielić na:\n",
        "* **uczalne** - zawierające zmienne uczalne (np. *w* i *b* w warstwie w pełni połączonej),\n",
        "* **nieuczalne** - takie, które wykonują pewne charakterystyczne działania na danych, jednak nie potrzebują do tego zmiennych, które będą uczone w trakcie propagacji gradientu.\n",
        "\n",
        "Poniżej zaprezentowane zostały popularne operacje uczalne i nieuczalne.\n",
        "\n",
        "**Uwaga**\n",
        "Wszystkie operacje są reprezentowane jako klasy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi5VgRQ7peBQ"
      },
      "source": [
        "### Uczalne\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnh4-j1XtP8k"
      },
      "source": [
        "Dzięki predefiniowanym warstwom nie ma potrzeby samodzielnej deklaracji nowych zmiennych. Wszystkie zmienne uczone są deklarowane (zgodnie z implementacją danej warstwy) wewnątrz obiektu, a następnie przechowywane.\n",
        "\n",
        "Do zmiennych uczonych można dostać się poprzez własność *state_dict* (lub *parameters*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI5eoguKtxCy"
      },
      "outputs": [],
      "source": [
        "m = torch.nn.Linear(5, 5)\n",
        "\n",
        "m.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfk3PAOvpjcK"
      },
      "source": [
        "#### Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSE1DNZErodm"
      },
      "source": [
        "Jest to warstwa w pełni połączona, która pobiera jako wejście wektor i produkuje na wyjściu wektor o długości równej rozmiarowi warstwy (liczby neuronów)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylb4JpMAr2DQ"
      },
      "outputs": [],
      "source": [
        "# definicja warstwy\n",
        "linear1 = torch.nn.Linear(8, 2)\n",
        "\n",
        "# inferencja\n",
        "x = torch.ones([8])\n",
        "y = linear1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "# zmienne uczone\n",
        "state_dict = linear1.state_dict()\n",
        "print(f\"Wagi w warstwie linear: {state_dict['weight']}\")\n",
        "print(f\"Bias'y w warstwie linear: {state_dict['bias']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEzIeQLKplLd"
      },
      "source": [
        "#### Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKyyxUqvuejZ"
      },
      "source": [
        "Warstwa w pełni połączona dobrze sprawdza się przy danych jednowymiarowych. W przypadku danych wielowymiarowych (jak obrazy) korzystanie z nich byłoby bardzo kosztowne obliczeniowo. Aby wykonać pojedynczą operację *Linear* z 128 neuronami na obrazie o rozmiarach (256, 256, 3) należałoby zadeklarować  256 * 256 * 3 * 128 = 25165824 zmiennych uczonych.\n",
        "\n",
        "Popularnym rozwiązaniem efektywnego przetwarzania danych wielowymiarowych są operacje konwolucji ([link do wizualizacji](https://github.com/vdumoulin/conv_arithmetic)). Konwolucja (inaczej splot) w sieciach neuronowych intuicyjnie jest, tak samo jak *Linear*, kombinacją liniową danego podobszaru danych wielowymiarowych i zmiennych uczonych (inaczej *kernel*).\n",
        "\n",
        "Konwolucja w PyTorch posiada szereg parametrów takich jak:\n",
        "* liczba kanałów wejściowych - liczba kanałów w obrazie wejściowym,\n",
        "* liczba kanałów wyjściowych - liczba kanałów \"wyprodukowana\" przez konwolucję,\n",
        "* kernel_size - rozmiar kernela,\n",
        "* stride - \"rozstrzał\" przetwarzanego podobszaru (patrz link do github),\n",
        "* padding - dopełnienie dodane do wszystkich czterech stron danych wejściowych. Domyślnie: 0,\n",
        "\n",
        "W porównaniu do przykładu przytoczonego powyżej, konwolucja z 128 filtrami, rozmiarem kernela równym (3, 3), dla takich samych danych wejściowych zawierałaby 3 * 3 * 3 * 128 = 3456, czyli ponad 7281 (!) razy mniej niż w przypadku *Linear*. Ponadto, w przetwarzaniu danych, w których zachodzą lokalne zależności (na obrazie sąsiadujące piksele reprezentują zazwyczaj ten sam obiekt) konwolucja sprawdza się o wiele lepiej niż *Linear*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGMUqvtcwFQe"
      },
      "outputs": [],
      "source": [
        "# definicja warstwy\n",
        "conv1 = torch.nn.Conv2d(128, 128, (3, 3), (2, 2), 1)\n",
        "\n",
        "# inferencja (przy pierwszym wywołaniu warstwy Linear1 zostaną stworzone zmienne uczone)\n",
        "x = torch.ones([10, 128, 128, 3])\n",
        "y = conv1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "# zmienne uczone\n",
        "state_dict = conv1.state_dict()\n",
        "print(f\"Wagi w warstwie conv: {state_dict['weight'].shape}\")\n",
        "print(f\"Bias'y w warstwie conv: {state_dict['bias'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3fPzepapfuY"
      },
      "source": [
        "### Nieuczalne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMV7LJQeRuXG"
      },
      "source": [
        "Warstwy nieuczalne zazwyczaj wykonują pewne operacje techniczne, typu zmiana kształtu, skalowanie danych, lub są wykorzystywane w **regularyzacji** (o czym będzie mowa na kolejnych zajęciach)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIl-axl0pu0s"
      },
      "source": [
        "#### Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoDcI-1sRtFq"
      },
      "source": [
        "Jest to jedna z popularniejszych metod regularyzacji, polegająca na wykonaniu pewnej operacji na małym wycinku danych. Przykładowo MaxPooling2D, podobnie jak konwolucja 2D (patrz wizualizacje), wybiera podobszar obrazu o jakichs wymiarach (np. 2x2) a następnie wybiera maksymalny obiekt z tego okna, tworząc nowy obraz (np. zmniejszony 2-krotnie). Istnieją również inne metody poolingu:\n",
        "\n",
        "* average - z okna obliczana jest średnia,\n",
        "* median - z okna obliczana jest mediana,\n",
        "* minimum - z okna wybierana jest najmniejsza wartość,\n",
        "* itp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmJStBb_zTO0"
      },
      "outputs": [],
      "source": [
        "# definicja warstwy\n",
        "mp1 = torch.nn.MaxPool2d((2, 2), (2, 2))\n",
        "\n",
        "# inferencja (przy pierwszym wywołaniu warstwy Linear1 zostaną stworzone zmienne uczone)\n",
        "x = torch.ones([10, 128, 128, 3])\n",
        "y = mp1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2C6kjTBpw3w"
      },
      "source": [
        "#### Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2_3pL2QSz4M"
      },
      "source": [
        "Flatten jest prostą funkcją spłaszczającą **każdy element w batchu**. Przykładowo dla grupy 10 obrazów o pewnych wymiarach wyprodukowanych zostanie 10 wektorów (spłaszczonych do wektorów obrazów)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5rs9OqBzoCt"
      },
      "outputs": [],
      "source": [
        "# definicja warstwy\n",
        "ft1 = torch.nn.Flatten()\n",
        "\n",
        "# inferencja (przy pierwszym wywołaniu warstwy Linear1 zostaną stworzone zmienne uczone)\n",
        "x = torch.ones([10, 128, 128, 3])\n",
        "y = ft1(x)\n",
        "\n",
        "# rozmiar wejściowego oraz wyjściowego tensora\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMqJe-T1oY-9"
      },
      "source": [
        "## Proces uczenia sieci neuronowej"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EorLINSXTTcE"
      },
      "source": [
        "Proces uczenia sieci neuronowych składa się z kilku części. Po inicjalizacji modelu oraz zbioru danych następuje uczenie modelu składające się z wielu **epok**. Epoka to pojedyncze przeiterowanie po całym zbiorze danych (podzbiory treningowe i walidacyjne). Przy czym model jest uczony (bład jest propagowany) tylko na zbiorze treningowym. **Nigdy na zbiorach walidacyjnym i testowym.** Proces uczenia sieci neuronowej składa się (najczęściej) następujących części:\n",
        "\n",
        "1. Inicjalizacja modelu,\n",
        "2. Inicjalizacja zbioru danych,\n",
        "3. Pętla treningowa,\n",
        "  1. Uczenie na zbiorze treningowym (raz!),\n",
        "  2. Ocena modelu na zbiorze walidacyjnym,\n",
        "4. Ocena modelu na zbiorze testowym (opcjonalne)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qro02c56Uskh"
      },
      "source": [
        "#### Inicjalizacja modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgzk0y0GU3Ty"
      },
      "source": [
        "**Uwaga:** Jeśli model składa się z następujących po sobie operacji, można opakować go dla wygody w strukturę *Sequential*, tak jak pokazano poniżej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZWoSMEeHhhF"
      },
      "outputs": [],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IxiftCDUuVn"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn.modules.activation import ReLU\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Model który na wejściu otrzymuje obraz a na wyjściu produkuje skalar\n",
        "\n",
        "        W skład modelu wchodzą 3 warstwy konwolucyjne o rozmiarach 64, 32, 16 (out_channels),\n",
        "        każda z rozmiarem kernela 5x5 oraz stride 2x2 (czyli obraz po każdej warstwie będzie 2 razy mniejszy)\n",
        "        potem następuje spłaszczenie obrazu do wektora i przetwarzanie warstwami w pełni połączonymi.\n",
        "        Wszystkie warstwy (oprócz wyjściowej) korzystają z funkcji aktywacji 'relu'\n",
        "        \"\"\"\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=5, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=64, out_features=32),\n",
        "            ReLU(),\n",
        "            nn.Linear(in_features=32, out_features=10),\n",
        "            ReLU(),\n",
        "            nn.Linear(in_features=10, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_relu_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "\n",
        "model = MyModel()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBfKk6KSWWXF"
      },
      "source": [
        "#### Inicjalizacja zbioru danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z242L-5DWZBc"
      },
      "source": [
        "Jako zbiór danych wykorzystany zostanie zaprezentowany wcześniej zbiór **MNIST**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZQ0CdUiWnbZ"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUyzOt0OWYeX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBmDlmOAf3b7"
      },
      "source": [
        "### Proces uczenia sieci neuronowej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUDPmj0bHhhG"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmE-IwkOZMUY"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4kmh8WItrUK"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM_SpGu7ejES"
      },
      "source": [
        "#### Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMB9DnMVeppt"
      },
      "source": [
        "Stwórz sieć neuronową składającą się z:\n",
        "\n",
        "* 3 warstw konwolucyjnych (kernel size = 5, liczba filtrów = 128, 64, 32, **bez stride (stride=1)**, aktywacja = relu, **padding='1'**)\n",
        "* 3 warstw Max Pooling-u, każda znajdująca się za kolejną warstwą konwolucyjną (pool size = 2, **stride = 2**, padding=1, funkcja aktywacji: relu) (tzn. Conv2D -> MaxPooling2D -> Conv2D -> MaxPooling2D -> ...),\n",
        "* 3 warstw w pełni połączonych (rozmiary: 512, 128, **liczba klas**, funkcja aktywacji: relu)\n",
        "\n",
        "Przetestuj swoją sieć na następujących zbiorach danych:\n",
        "\n",
        "* Cifar 10\n",
        "* Cifar 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbK4okcB0Dqs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            # TODO\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.blocks(x)\n",
        "\n",
        "\n",
        "model = NeuralNetwork(10)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "1W1ZAdDjLh0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# TODO - init dataset"
      ],
      "metadata": {
        "id": "F0BX6tH9Nua_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# TODO - init dataloaders"
      ],
      "metadata": {
        "id": "wjiYpQJYOH5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - train networks"
      ],
      "metadata": {
        "id": "TfYLcHWsPYZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZAkvIIF0ub9"
      },
      "source": [
        "## Pretrenowane sieci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jGE3QZP0xLF"
      },
      "source": [
        "Biblioteka udostępnia również **pretrenowane** modele. Tzn. takie, które zostały już wyuczone na pewnych zbiorach danych.\n",
        "\n",
        "Istnieje wiele znanych, pretrenowanych sieci neuronowych:\n",
        "\n",
        "* ResNet (w wersji 50, 100, itp.),\n",
        "* Inception (V2, V3),\n",
        "* VGG (16, 19),\n",
        "* MobileNet,\n",
        "* LinearNet\n",
        "\n",
        "Poniżej zaprezentowany został przykład użycia jednej z nich.\n",
        "\n",
        "**Uwaga:** wgrywanie plikow działa poprawnie w przeglądarce google chrome. Na przeglądarkach FireFox można bezpośrednio wgrać pliki korzystając z zakładki \"files\" po lewej strone (rozwijany pasek nawigacji - strzałka w prawo). Taki plik można wczytać bezpośrednio korzystając z: Image.open('path_to_file.png').\n",
        "\n",
        "**Uwaga:** czasem niezbędne jest dwukrotne wykonanie poniższego skryptu, aby można było skorzystać z widgetu do wgrywania pliku."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# Using pretrained weights:\n",
        "resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "resnet50(weights=\"IMAGENET1K_V1\")\n",
        "resnet50(pretrained=True)  # deprecated\n",
        "resnet50(True)  # deprecated\n",
        "\n",
        "# Using no weights:\n",
        "resnet50(weights=None)\n",
        "resnet50()\n",
        "resnet50(pretrained=False)  # deprecated\n",
        "resnet50(False)  # deprecated"
      ],
      "metadata": {
        "id": "XpyqNOZVSMYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "\n",
        "# wybranie sciezki do pliku (jakikolwiek obraz z google)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# wyświetlenie obrazu\n",
        "im = Image.open(BytesIO(uploaded['cat.jpg']))\n",
        "# dla przeglądarek FireFox\n",
        "# im = Image.open('cat.jpg')\n",
        "IPython.display.display(im)"
      ],
      "metadata": {
        "id": "feu3XU09SRL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCelF4b84AX1"
      },
      "outputs": [],
      "source": [
        "# przygotowanie obrazka\n",
        "im_numpy = np.array(im.resize((224, 224)))  # rozmiar który przyjmuje ResNet\n",
        "im_torch = torch.Tensor(im_numpy).permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "# załadowanie pretrenowanego modelu i jego inferencja\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "weights = ResNet50_Weights.IMAGENET1K_V1\n",
        "model = resnet50(weights=weights)\n",
        "model.eval()\n",
        "\n",
        "print(im_torch.shape)\n",
        "pred = model(im_torch)\n",
        "\n",
        "# pobranie wyniku z sieci neuronowej\n",
        "print(torch.argmax(pred, -1).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2mA5jOM-CR9"
      },
      "source": [
        "Zgodnie z klasami zawartymi w zbiorze danych ImageNet, odpowiedź 284 oznacza \"Kot syjamski\".\n",
        "\n",
        "Przykładowe klasy:\n",
        "\n",
        "* 21: 'kite',\n",
        "* 22: 'bald eagle, American eagle, Haliaeetus leucocephalus',\n",
        "* 23: 'vulture',\n",
        "* 243: 'bull mastiff',\n",
        "* 244: 'Tibetan mastiff',\n",
        "* 245: 'French bulldog',\n",
        "* 282: 'tiger cat',\n",
        "* 283: 'Persian cat',\n",
        "* 284: 'Siamese cat, Siamese',\n",
        "* 285: 'Egyptian cat',\n",
        "\n",
        "Wszystkie obecne w ImageNet klasy: [link](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X__La7lM-VXh"
      },
      "source": [
        "#### Zadanie 3\n",
        "\n",
        "Spróbuj wykorzystać dowolną inną pretrenowaną sieć neuronową, zgodnie z powyższym schematem. Możesz spróbować załadować inny obraz.\n",
        "\n",
        "Dostępne pretrenowane modele: [link](https://pytorch.org/vision/stable/models.html)\n",
        "\n",
        "**Uwaga:** zwróć uwagę na rozmiary danych, które przyjmują poszczególne sieci neuronowe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFNQQ8cr-qra"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-snum",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
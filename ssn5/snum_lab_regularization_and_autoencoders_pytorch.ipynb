{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Wprowadzenie do sieci neuronowych i uczenia maszynowego\n",
        "\n",
        "## Lab: Własne moduły w PyTorch, regularyzacja i autoenkodery\n",
        "\n",
        "---\n",
        "\n",
        "**Autorzy materiałów:** Marek Wydmuch, Iwo Błądek, Jakub Bednarek<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji.\n"
      ],
      "metadata": {
        "id": "o8aSyboqZ40M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "\n",
        "- zapoznanie się z tworzeniem własnych modułów w PyTorch\n",
        "- wykorzystanie podstawowych mechanizmów regularyzacji: Dropout i Batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8ToIOrDr7A8",
        "outputId": "1a76b3ba-cd05-4e5e-f158-bf20a6bc968d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128)"
      ],
      "metadata": {
        "id": "Ru_6o1FtcJb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Własne moduły (warstwy sieci neuronowych) w PyTorch\n",
        "\n"
      ],
      "metadata": {
        "id": "6704VllCgACt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na poprzednich zajęciach używaliśmy gotowych modułów reprezentujących warstwy sieci neuronowych by stworzyć główny moduł naszego modułu.\n",
        "\n",
        "W PyTorch nie ma żadnej hierarchii modułów (jak np. w TensorFlow czy Keras, gdzie API jest podzielone na modele i warstwy). Każdy moduł może używać innych modułów jako swoich komponentów.\n",
        "\n",
        "Poniżej przykładowa implementacja modułu warstwy liniowej całkowicie od podstaw."
      ],
      "metadata": {
        "id": "Djf05n2ljXCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class CustomLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(CustomLayer, self).__init__()\n",
        "        # Parametry (wagi) naszego modułu\n",
        "        self.weights = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
        "        # Inicjalizacja wag\n",
        "        nn.init.xavier_normal_(self.weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return torch.mm(x, self.weights)\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            CustomLayer(784, 512),\n",
        "            nn.ReLU(),\n",
        "            CustomLayer(512, 512),\n",
        "            nn.ReLU(),\n",
        "            CustomLayer(512, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "oOZf2KXSf_zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup naszego modelu\n",
        "model = CustomModel(num_classes=10).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(pred, target):\n",
        "    return (pred.argmax(1) == target).type(torch.float).sum().item()\n",
        "\n",
        "# Pętla treningowa i testowa\n",
        "def train_and_test(\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        model,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        metric=None,\n",
        "        epochs=10,\n",
        "        verbose=False\n",
        "    ):\n",
        "    epochs_history = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_metric = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data)\n",
        "            loss = criterion(pred, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if verbose and batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "            train_metric += metric(pred, target)\n",
        "        if verbose:\n",
        "            train_loss /= len(train_loader.dataset)\n",
        "            train_metric /= len(train_loader.dataset)\n",
        "            print(f\"Train loss: {train_loss:.4f}\")\n",
        "            print(f\"Train {metric.__name__}: {train_metric:.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        test_metric = 0\n",
        "        test_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "            pred = model(data)\n",
        "            loss = criterion(pred, target)\n",
        "            test_loss += loss.item() * data.size(0)\n",
        "            test_metric += metric(pred, target)\n",
        "        if verbose:\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            test_metric /= len(test_loader.dataset)\n",
        "            print(f\"Test loss: {test_loss:.4f}\")\n",
        "            print(f\"Test {metric.__name__}: {test_metric:.4f}\")\n",
        "            print(\"-------------------------------\")\n",
        "\n",
        "        epochs_history.append({\n",
        "          \"epoch\": epoch,\n",
        "          \"train_loss\": train_loss,\n",
        "          f\"train_{metric.__name__}\": train_metric,\n",
        "          \"test_loss\": test_loss,\n",
        "          f\"test_{metric.__name__}\": test_metric\n",
        "        })\n",
        "    return epochs_history\n",
        "\n",
        "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)"
      ],
      "metadata": {
        "id": "67epDtrvAd-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 1\n",
        "\n",
        "Stwórz prosty model\n",
        "- warstwy konwolucyjnej (Conv2D): 32 filtry 3x3,\n",
        "- konwolucyjnej: 64 filtry 3x3,\n",
        "- warstwy MaxPooling (MaxPooling2D): 2x2\n",
        "- warstwy ukrytej gęstej (Dense): 128 neuronów,\n",
        "- warstwy wyjściowej.\n",
        "\n",
        "Ważne:\n",
        "- w każdej warstwie poza warstwą wyjściową funkcją aktywacji powinno być relu,\n",
        "- funkcja aktywacji dla warstwy wyjściowej to softmax,\n",
        "- między częścią konwolucyjną a gęstą trzeba spłaszczyć tensor przy pomocy warstwy `nn.Flatten`."
      ],
      "metadata": {
        "id": "a0X-U_vfAEde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "\n",
        "    # Inicjalizacja parametrów, która znacząco poprawi początkowe uczenie\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = SimpleModel(num_classes=10).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, metric=accuracy, epochs=10, verbose=True)"
      ],
      "metadata": {
        "id": "Oi-_IKIhBLbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 2\n",
        "\n",
        "Na podstawie powyższego przykładu stwórz moduł bloku ResNet.\n",
        "Zadbaj o to by rozmiary tensorów po warstwach konwolucyjnych się nie zmieniały.\n",
        "\n",
        "![resnet](https://miro.medium.com/max/1000/1*6HDuqhUzP92iXhHoS0Wl3w.png)\n",
        "\n",
        "Zmodyfikuj model z zadania 1, zamieniając warstwy konwolucyjne na dwa modele bloku ResNet.\n",
        "\n"
      ],
      "metadata": {
        "id": "FTjsGT9QGCtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "xMZZ-2SIPz7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularyzacja\n",
        "\n",
        "### Zadanie 3\n",
        "\n",
        "Rozszerz model stworzony w zadaniu 1 o dwie warstwy Dropout (nn.Dropout):\n",
        "- jedna po warstwie MaxPooling (wartość współczynnika odrzucenia 0.25)\n",
        "- druga po gęstej warstwie ukrytej (Dense), wartość współczynnika odrzucenia 0.5.\n",
        "- dodaj opcję włączenia i wyłączenia dropoutu jako argument konstruktora modułu modelu.\n",
        "\n"
      ],
      "metadata": {
        "id": "UqIntmmWEUaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "z_7oo2C5H8sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 4\n",
        "Rozszerz model stworzony w poprzednich zadaniach o dwie warstwy Batch normalization (nn.BatchNorm2d) po warstwach konwolucyjnych. Dodaj opcję włączenia i wyłączenia dropoutu jako argument konstruktora modułu modelu.\n",
        "\n"
      ],
      "metadata": {
        "id": "xRuy70AoHEAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "6pzIwT0tH9fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 5\n",
        "Porównaj model bez oraz z różnych kombinacjami technik regularyzacji (z dropoutem ale bez batch norm., bez dropout ale z batch norm., z dropoutem i z batch norm.).\n",
        "Stwórz cztery wykresy:\n",
        "- błąd funkcji celu dla zbioru treningowego,\n",
        "- błąd funkcji celu dla zbioru walidacyjnego,\n",
        "- trafność klasyfikacji dla zbioru treningowego,\n",
        "- trafność klasyfikacji dla zbioru walidacyjnego."
      ],
      "metadata": {
        "id": "gzizHr8YHSge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "x9JBF4euH9vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoenkodery\n",
        "\n",
        "Ideę autoenkodera prezentuje poniższy rysunek:\n",
        "![label-autoencoder_schema](https://drive.google.com/uc?export=view&id=1Ai2ER1ppKfnHg5t_lCwO_fvvFNe59dgd)\n",
        "\n",
        "Widzimy tutaj, że obrazek ze zbioru MNIST o rozmiarze 28 x 28 został skompresowany przez **enkoder** do tensora o rozmiarze 5 x 2. Tensor ten nosi nazwę **wektora zmiennych ukrytych** (ang. latent vector). Następnie **dekoder** przyjął ten wektor na wejście, i odtworzył oryginalny obrazek. Jest to przykład zadania **autoasocjacji**, gdzie celem uczenia sieci neuronowej jest możliwie wierne odtworzenie danych wejściowych. Zadanie to może się wydawać bez sensu w odosobnieniu (po co odtwarzać coś, co już mamy?), jednak to co nas najbardziej interesuje w autoenkoderze to wektor zmiennych ukrytych. Jako że skompresowaliśmy cały obrazek do 10 wartości, to by realistyczne odtworzenie z nich oryginalnego obrazka było możliwe, każda z tych wartości musi 1) zawierać o nim możliwie dużo informacji, 2) nieistotne detale oryginalnego obrazka muszą zostać pominięte. Wyciągnęliśmy więc z danych informacyjną \"esencję\", pozbyliśmy się redundatnych elementów opisu.\n",
        "\n",
        "<br>\n",
        "\n",
        "Najważniejszą cechą autoenkodera jest właśnie **uczenie się efektywnego kodowania danych**, co zazwyczaj wiąże się z redukcją wymiarowości (tzw. 'undercomplete autoencoders'), choć można też uczyć autoenkodery o kodowaniu zwiększającym wymiarowość (tzw. 'overcomplete autoencoders'). Skupimy się na autoenkoderach zmniejszających wymiarowość, bo ich uczenie jest znacznie prostsze. W przeciwieństwie do np. PCA kodowanie uzyskane przez taki autoenkoder może być nieliniowe, tak więc zmienne ukryte mają więcej elastyczności w reprezentacji danych. Selekcja atrybutów, której podstawy omawialiśmy wcześniej na przedmiocie, również redukuje wymiarowość, ale nie zmienia informacji w atrybutach. W ogólności techniki redukcji wymiarowości tworzą zupełnie nowe atrybuty ze starych (np. $Y_1 = 0.5X_1 - 0.25X_2^2 + \\log_2 X_3$, gdzie $Y_1$ to nowy atrybut, a $X_i$ to oryginalne atrybuty). Wiele zastosowań autoenkoderów buduje właśnie na tej zdolności, a także na tym, że dzięki procesowi uczenia sieci tworzymy metodę redukcji wymiarowości zoptymalizowaną do konkretnego problemu.\n",
        "\n",
        "<br>\n",
        "\n",
        "Autoenkodery mają wiele potencjalnych zastosowań, przykładowo:\n",
        "* Redukcja wymiarowości - uczymy autoenkoder w trybie autoasocjacji, i naszym celem jest zmniejszenie wymiarowości danych, czyli zastąpienie oryginalnego obiektu jego wektorem zmiennych ukrytych. Można użyć jako alternatywy dla selekcji atrybutów i dedykowanych metod redukcji wymiarowości (PCA, LDA, etc.).\n",
        "* Grupowanie - uczymy autoenkoder w trybie autoasocjacji, wykorzystujemy wektory zmiennych ukrytych uzyskane dla danych uczących jako wejście do algorytmu grupowania (np. k-means).\n",
        "* Wyszukiwanie informacji - uczymy autoenkoder w trybie autoasocjacji, wykorzystujemy wektor zmiennych ukrytych jako hasz obiektu. Jeżeli chcemy znaleźć w bazie danych obiekty podobne do zadanego obiektu $X$, to generujemy wektor zmiennych ukrytych (hasz) $X$ przy użyciu enkodera i szukamy obiektów w zbiorze o najbardziej zbliżonych haszach. Technika ta nazywana jest haszowaniem semantycznym.\n",
        "* Wykrywanie anomalii - uczymy autoenkoder w trybie autoasocjacji wyłącznie na przypadkach \"normalnych\". Liczymy na to, że jak kiedykolwiek autoenkoder dostanie do przetworzenia przypadek odstający/anomalię, to nie da rady jej dobrze zrekonstruować i błąd będzie wysoki (właśnie przez to, że nie miał szansy się na nich nauczyć).\n",
        "* Generowanie danych - uczymy autoenkoder w trybie autoasocjacji, a następnie jak chcemy uzyskać różne warianty danego obrazu/obiektu, to modyfikujemy jego wygenerowany przez enkoder wektor zmiennych ukrytych, i dajemy go do przetworzenia dekoderowi. Możemy też po prostu losowo próbkować przestrzeń wektorów ukrytych i obserwować wyniki po przetworzeniu przez dekoder. Przy odrobinie szczęścia jakaś zmienna ukryta może np. odpowiadać za wyraz twarzy człowieka, i zmieniając wartości tej zmiennej możemy zmieniać wyłącznie wyraz twarzy człowieka na zdjęciu. Do tego zadania zazwyczaj wykorzystywany jest zmodyfikowany wariant autoenkodera: autoenkoder wariacyjny.\n",
        "* Odszumianie - uczymy autoenkoder w trybie heteroasocjacji: *zaszumiony obraz* -> *oryginalny obraz*. Liczymy na to, że enkoder i dekoder nauczą się poprawnie rozpoznawać szum jako element redundantny, nieniosący żadnej informacji.<br>\n",
        "![label-autoencoder_denoising](https://drive.google.com/uc?export=view&id=1a1fP7CWjzKSwo0txUBUMwaxTrpt6LzyH)\n",
        "\n"
      ],
      "metadata": {
        "id": "zRXbmNFsKxsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 6\n",
        "\n",
        "Zaimplementuj autoenkoder o następującej architekturze:\n",
        "* Enkoder: Dense(100) -> Dense(50) -> Dense(10) (wektor zmiennych ukrytych).\n",
        "* Dekoder: Dense(50) -> Dense(100) -> Dense(784) (wyjściowy zrekonstruowany obrazek)\n",
        "\n",
        "gdzie Dense(n) oznacza warstwę w pełni połączoną z *n* neuronami i funkcją aktywacji ReLU. Jako miarę błędu przyjmij MSE."
      ],
      "metadata": {
        "id": "ApWipgI_LFh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Zepewnij, że wejście jest spłaszczone do jednego wymiaru\n",
        "        x = x.view(-1, 784)\n",
        "\n",
        "        # Encode\n",
        "        encoded = self.encoder(x)\n",
        "        # Decode\n",
        "        decoded = self.decoder(encoded)\n",
        "\n",
        "        # Przywróć wyjście do oryginalnego wymiaru\n",
        "        decoded = decoded.view(-1, 1, 28, 28)\n",
        "\n",
        "        return decoded\n",
        "\n",
        "\n",
        "# Zmodyfikuj pętlę treningowa i testowa\n",
        "def train_and_test(\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        model,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        epochs=10,\n",
        "        verbose=False,\n",
        "    ):\n",
        "    epochs_history = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Oblicz loss (pamiętaj, że jest to zadanie autoasocjacji)\n",
        "            loss = ...\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if verbose and batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "        if verbose:\n",
        "            train_loss /= len(train_loader.dataset)\n",
        "            print(f\"Train loss: {train_loss:.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        test_metric = 0\n",
        "        test_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data = data\n",
        "\n",
        "            # Oblicz test loss (pamiętaj, że jest to zadanie autoasocjacji)\n",
        "            test_loss = ...\n",
        "\n",
        "            test_loss += loss.item() * data.size(0)\n",
        "        if verbose:\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            test_metric /= len(test_loader.dataset)\n",
        "            print(f\"Test loss: {test_loss:.4f}\")\n",
        "            print(\"-------------------------------\")\n",
        "\n",
        "        epochs_history.append({\n",
        "          \"epoch\": epoch,\n",
        "          \"train_loss\": train_loss,\n",
        "          \"test_loss\": test_loss,\n",
        "        })\n",
        "    return epochs_history\n",
        "\n",
        "model = Autoencoder()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "_ = train_and_test(train_loader, test_loader, model, optimizer, criterion, epochs=10, verbose=True)"
      ],
      "metadata": {
        "id": "8ZCTt7EiLFNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 7\n",
        "\n",
        "Użyj zaimplementowanego w poprzednim zadaniu autoenkodera by zaobserwować jak zmienia się odtwarzany obraz gdy zmienia się tylko jeden element wektora zmiennych ukrytych. Zadanie wykonywane jest w następujących krokach:\n",
        "1. Użyj nauczonego enkodera z poprzedniego zadania na przypadku uczącym wybranej cyfry (dowolnej) by uzyskać wektor zmiennych ukrytych.\n",
        "2. Wybierz konkretną zmienną ukrytą w tym wektorze, np. tę o indeksie 0.\n",
        "3. W pętli podstawiaj różne wartości do tej zmiennej wektora z pewnym krokiem, i obserwuj obrazki generowane przez dekoder."
      ],
      "metadata": {
        "id": "VrWS4dxeNVeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = train_data[0][0]\n",
        "print(\"Original image\")\n",
        "plt.imshow(example.reshape((28, 28)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Po uczeniu wykonanym w poprzednim zadaniu, mamy dostęp do już nauczonych składowych sieci\n",
        "latent_vector = # Użyj enkodera\n",
        "output = # Użyj dekodera\n",
        "\n",
        "print(\"Reconstructed image\")\n",
        "plt.imshow(output.detach().numpy().reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f\"latent_vector: {latent_vector}\")\n",
        "\n",
        "for e in torch.linspace(torch.min(latent_vector), torch.max(latent_vector), 11):\n",
        "    print(f\"e: {e}\")\n",
        "\n",
        "    # Zmień wektor zmiennych ukrytych, ustawiając wartość e w odpowiednim polu wektora\n",
        "    ...\n",
        "    # Użyj dekodera by wygenerować obrazek z nowego wektora zmiennych ukrytych\n",
        "    ...\n",
        "    # Pokaż wynikowy obrazek\n",
        "    ..."
      ],
      "metadata": {
        "id": "ucUkv-MjNvmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 8\n",
        "\n",
        "Wykorzystaj kod z poprzednich zadań by nauczyć autoenkoder odszumiania. Parę uwag:\n",
        "* Musisz zmodyfikować zbiór uczący poprzez dodanie sztucznego szumu. Można to zrobić albo poprzez zmianę wartości kilku losowych pikseli w każdym obrazku, albo dodanie macierzy z małymi losowo generowanymi liczbami do obrazka (do każdego obrazka innej!). Oczekiwaną odpowiedzą podczas uczenia będzie oryginalny obrazek bez szumu.\n",
        "* Architektura enkodera i dekodera może pozostać bez zmian, ale będziesz musiał ją nauczyć na nowym zbiorze danych, tak więc by nie psuć wyników z zadania nr 1 sugeruję przeklejenie odpowiedniego kodu tutaj.\n",
        "* Zademonstruj działanie odszumiania poprzez pokazanie przypadku z szumem, a następnie zrekonstruowanego obrazka bez szumu po przetworzeniu przez autoenkoder."
      ],
      "metadata": {
        "id": "NQ8Iwz3sNsNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "v_OMeKBPNuGZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-snum",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
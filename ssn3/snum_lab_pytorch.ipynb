{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Wprowadzenie do sieci neuronowych i uczenia maszynowego\n",
        "\n",
        "## Lab: Wprowadzenie do biblioteki PyTorch\n",
        "\n",
        "---\n",
        "\n",
        "**Autorzy materiałów:** Marek Wydmuch, Jakub Bednarek<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tVMrm99g5w"
      },
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dlaczego Colab\n",
        "\n",
        "* Obliczenia wykonywane przez sieci są wymagające obliczeniowo, a ich specyfika sprawia, że można je dużo szybciej wykonywać na GPU.\n",
        "* Nie każdy ma odpowiedni GPU w swoim komputerze (rekomendowane GPU to GPU firmy Nvidia, alternatywnie układy Apple Silicon).\n",
        "* Dlatego sugerowany sposób pracy będzie przez Colab na którym jest skonfigurowane środowisko wraz ze skromnym GPU."
      ],
      "metadata": {
        "id": "xfsz6tAYdsIX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń\n",
        "\n",
        "* wprowadzenie biblioteki PyTorch,\n",
        "* ukazanie różnic i podobieństw pomiędzy NumPy a PyTorch,\n",
        "* algorytm wstecznej propagacji błędu w PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0AoiF16OTow"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "PyTorch to potężna biblioteka do uczenia maszynowego i głębokiego uczenia, stworzona przez Meta (dawniej Facebook).\n",
        "U podstaw jest to biblioteka implementująca operacje na tensorach (tablicach) na wzór NumPy, którego poszczególne elementy zostały zaprezentowane na poprzednich zajęciach.\n",
        "PyTorch oferuje dynamiczne podejście do tworzenia sieci neuronowych, co sprawia, że jest szczególnie popularny w środowisku badawczym i akademickim.\n",
        "\n",
        "Główne cechy PyTorch:\n",
        "- Natywna integracja z Python i łatwa współpraca z bibliotekami jak NumPy\n",
        "- Imperatywny styl programowania, który jest bardziej naturalny dla programistów Pythona\n",
        "- Dynamiczne grafy obliczeniowe (define-by-run), które ułatwiają debugowanie\n",
        "- Wsparcie dla CPU i GPU, z automatycznym przełączaniem między nimi\n",
        "- Rozbudowany ekosystem narzędzi i bibliotek (torchvision, torchaudio, torchtext)\n",
        "\n",
        "Aby rozpocząć pracę z PyTorch w Colab, wystarczy zaimportować bibliotekę:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ovUb2T9CbQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd3ac7f-0945-47ed-fc5b-181498f056e7"
      },
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jeśli nie korzystasz z Colab odwiedź https://pytorch.org/get-started/locally/ by dowiedzieć się jak zainstalować odpowiednią wersję dla swojego środowiska."
      ],
      "metadata": {
        "id": "3WuWss5Venrm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyOQAsNXECp0"
      },
      "source": [
        "## Używanie biblioteki PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBy3wd9GSXa0"
      },
      "source": [
        "PyTorch domyślnie używa tensorów (tablic) z API bardzo podobnym do NumPy, poznanego na poprzednich zajęciach.\n",
        "\n",
        "Poniżej przedstawione zostało porównanie wykonania tego samego zadania w NumPy oraz w PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl7PpJ5OOVNj"
      },
      "source": [
        "# Import biblioteki numpy\n",
        "import numpy as np\n",
        "\n",
        "# NumPy\n",
        "print(\"NumPy:\")\n",
        "x_np = np.array([[1., 2.], [3., 4.]])\n",
        "y_np = np.array([[5., 6.], [7., 8.]])\n",
        "z_np = np.multiply(x_np, y_np)\n",
        "print(f\"x:\\n{x_np}\")\n",
        "print(f\"y:\\n{y_np}\")\n",
        "print(f\"x * y:\\n{z_np}\")\n",
        "\n",
        "# PyTorch\n",
        "print(\"\\nPyTorch:\")\n",
        "x_torch = torch.tensor([[1., 2.], [3., 4.]])\n",
        "y_torch = torch.tensor([[5., 6.], [7., 8.]])\n",
        "z_torch = torch.mul(x_torch, y_torch)  # lub po prostu x_torch * y_torch\n",
        "print(f\"x:\\n{x_torch}\")\n",
        "print(f\"y:\\n{y_torch}\")\n",
        "print(f\"x * y:\\n{z_torch}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W obu przypadkach uzyskamy identyczny wynik, ale PyTorch oferuje dodatkowo:\n",
        "\n",
        "- Automatyczne obliczanie gradientów (autograd)\n",
        "- Łatwe przenoszenie obliczeń na GPU\n",
        "- Zachowanie informacji o grafie obliczeniowym\n",
        "- Pełną integrację z debuggerem Pythona\n",
        "\n",
        "Inne przykłady składni bardzo podobnej do NumPy:"
      ],
      "metadata": {
        "id": "kgniwGZHgQsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Operacje są prawie identyczne jak w NumPy\n",
        "print(x_np + y_np)\n",
        "print(x_torch + y_torch)  # dodawanie\n",
        "\n",
        "print(x_np * y_np)\n",
        "print(x_torch * y_torch)  # mnożenie element-wise\n",
        "\n",
        "print(x_np @ y_np)\n",
        "print(x_torch @ y_torch)  # mnożenie macierzowe\n",
        "\n",
        "print(np.mean(x_np))\n",
        "print(torch.mean(x_torch))  # średnia\n",
        "\n",
        "print(np.sum(x_np, axis=0))\n",
        "print(torch.sum(x_torch, dim=0))  # suma wzdłuż wymiaru"
      ],
      "metadata": {
        "id": "eWLUWruQgPaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKGuFNGnTa9c"
      },
      "source": [
        "# Również w przypadku alokowania tablic/tensorów\n",
        "\n",
        "# Tablice zer\n",
        "arr_np = np.zeros([5, 5])\n",
        "arr_torch = torch.zeros(5, 5)\n",
        "\n",
        "# Tablice jedynek\n",
        "arr_np = np.ones([5, 5])\n",
        "arr_torch = torch.ones(5, 5)\n",
        "\n",
        "# Tablice ze zdefiniowanymi wartościami\n",
        "arr_np = np.array([1, 2, 3, 4, 5])\n",
        "arr_torch = torch.tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "# Tablice z losowymi wartościami z rozkładu normalnego\n",
        "arr_np = np.random.normal(0, 1, [5, 5])\n",
        "arr_torch = torch.randn(5, 5)  # standardowy rozkład normalny (mean=0, std=1)\n",
        "# Alternatywnie, z konkretną średnią i odchyleniem:\n",
        "arr_torch = torch.normal(mean=0, std=1, size=(5, 5))\n",
        "\n",
        "print('NumPy array:\\n', arr_np, '\\n')\n",
        "print('PyTorch array:\\n', arr_torch, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warto zauważyć kilka różnic między NumPy a PyTorch:\n",
        "\n",
        "- W PyTorch często pomijamy \"nawiasy\" przy definiowaniu wymiarów - używamy po prostu `torch.zeros(5, 5)` zamiast `torch.zeros([5, 5])` lub `torch.zeros((5, 5))`. Czyli kolejne wymiary są przekazywane jako kolejne argumenty a nie obiekt o typie sekwencji.\n",
        "- Zamiast array używamy tensor do tworzenia tensorów ze zdefiniowanymi wartościami.\n",
        "Dla rozkładu normalnego PyTorch oferuje zarówno `torch.randn()` (dla standardowego rozkładu normalnego) jak i bardziej ogólną funkcję `torch.normal()`.\n",
        "- Operacje po konkretnych wymiarach używają argumentu `dim` zamiast `axis`.\n",
        "\n",
        "Wszystkie te tensory mogą być łatwo przeniesione na GPU poprzez dodanie metody `.cuda()` lub `.to('cuda')`, na przykład:\n"
      ],
      "metadata": {
        "id": "rT4hyM6yhZ-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    arr_torch = arr_torch.cuda()\n",
        "arr_torch"
      ],
      "metadata": {
        "id": "xaCtOIE5hZRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Od teraz wszystkie operacje wykonywane na tym tensorze będą się automatycznie działy na GPU.\n",
        "\n",
        "**Ważne:** Jeśli dwa obiekty wchodzą ze sobą w interakcję muszą znajdować się na tym samym urządzeniu (albo oba na GPU, albo oba na CPU)."
      ],
      "metadata": {
        "id": "4YOWeRg-Fatp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDAxwKNDUMrH"
      },
      "source": [
        "### Zadanie 1\n",
        "\n",
        "Zaalokuj tablicę samych zer o wymiarze 2 x 2. Następnie utwórz tablicę jedynek o tym samym wymiarze (wykorzystaj funkcję ones_like)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnt4cj4vWhms"
      },
      "source": [
        "# alokacja zer\n",
        "z = ...\n",
        "\n",
        "# alokacja jedynek\n",
        "o = ...\n",
        "\n",
        "print(z)\n",
        "print(o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIo9g-OZI-jv"
      },
      "source": [
        "### Zmienne \"uczone\" i autograd w PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZW2QB-HJDxu"
      },
      "source": [
        "Drugim filarem biblioteki PyTorch, po operacjach na tensorach, jest autograd.\n",
        "Autograd to kluczowa funkcjonalność, która umożliwia automatyczne obliczanie gradientów. Jest to fundamentalny mechanizm używany w uczeniu głębokich sieci neuronowych.\n",
        "\n",
        "W PyTorch możemy oznaczać tensory, które mają brać udział w liczeniu gradientów poprzez `requires_grad=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpLPMsD0JeB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14f24fb-86f4-4c72-da5d-d526fabf813c"
      },
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)  # włączamy śledzenie gradientu\n",
        "#x = torch.tensor(2.0)  # to spowoduje błąd poniższego kodu\n",
        "print(f\"x = {x}\")\n",
        "print(f\"Czy x wymaga gradientu? {x.requires_grad}\")\n",
        "\n",
        "# Wykonujemy operacje matematyczne\n",
        "y = x * 2  # y = 2x\n",
        "z = y * y  # z = 4x²\n",
        "\n",
        "print(f\"\\ny = {y}\")\n",
        "print(f\"z = {z}\")\n",
        "\n",
        "# Obliczamy gradient dz/dx\n",
        "z.backward()\n",
        "\n",
        "# Sprawdzamy gradient (powinien być 16, bo dz/dx = 8x dla x=2)\n",
        "print(f\"\\nGradient dz/dx = {x.grad}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = 2.0\n",
            "Czy x wymaga gradientu? True\n",
            "\n",
            "y = 4.0\n",
            "z = 16.0\n",
            "\n",
            "Gradient dz/dx = 16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obliczamy gradient dz/dx\n",
        "z.backward()\n",
        "\n",
        "# Sprawdzamy gradient (powinien być 16, bo dz/dx = 8x dla x=2)\n",
        "print(f\"\\nGradient dz/dx = {x.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "9_0i7_7729UM",
        "outputId": "2f843e0a-818e-40bd-cca9-c96c30af64b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1625829060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Obliczamy gradient dz/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Sprawdzamy gradient (powinien być 16, bo dz/dx = 8x dla x=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nGradient dz/dx = {x.grad}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatywną metodą zdefiniowana zmiennej wymagającej liczenia gradientu\n",
        "# jest użycie klasy wrappującej parametr sieci neuronowej\n",
        "import torch.nn as nn\n",
        "\n",
        "x = nn.Parameter(torch.tensor(2.0))\n",
        "print(f\"x = {x}\")\n",
        "print(f\"Czy x wymaga gradientu? {x.requires_grad}\")\n",
        "\n",
        "# Wykonujemy operacje matematyczne\n",
        "y = x * 2  # y = 2x\n",
        "z = y * y  # z = 4x²\n",
        "\n",
        "print(f\"\\ny = {y}\")\n",
        "print(f\"z = {z}\")\n",
        "\n",
        "# Obliczamy gradient dz/dx\n",
        "z.backward()\n",
        "\n",
        "# Sprawdzamy gradient (powinien być 16, bo dz/dx = 8x dla x=2)\n",
        "print(f\"\\nGradient dz/dx = {x.grad}\")"
      ],
      "metadata": {
        "id": "uDM2kQrjoItG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45dcdda9-5afa-426f-9fb4-9e4a3cc8f87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = Parameter containing:\n",
            "tensor(2., requires_grad=True)\n",
            "Czy x wymaga gradientu? True\n",
            "\n",
            "y = 4.0\n",
            "z = 16.0\n",
            "\n",
            "Gradient dz/dx = 16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby potem wyzerować gradient ale nie usuwać samej zmiennej możemy ustawić go na `None`."
      ],
      "metadata": {
        "id": "Aznpgq5JkSyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad = None"
      ],
      "metadata": {
        "id": "eXGr0lNpkP_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sh_nuvpLfJu"
      },
      "source": [
        "### Funkcje aktywacji i straty w PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbUbMgx0LkXd"
      },
      "source": [
        "PyTorch jest biblioteką przygotowaną do **Machine Learningu**. Wiele operacji bardzo często się powtarza w wielu zagadnieniach, np. funkcje aktywacji, funkcje straty, metryki, rodzaje warstw (operacji), itp. Stąd, w bilbiotece tej możemy znaleźć już gotowe komponenty, które można z łatwością wykorzystać (więcej o tym na kolejnych zajęciach).\n",
        "\n",
        "Poniżej zaprezentowane zostały gotowe funkcje aktywacji oraz straty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Z84f4NMI0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2b6fc8-5a30-4f44-a05e-d8be30a2dba5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # funkcje aktywacji i inne operacje\n",
        "\n",
        "# 1. Funkcje aktywacji\n",
        "# Możemy używać ich na dwa sposoby:\n",
        "# a) Jako warstwy (zalecane w modelach, o warstwach więcej na kolejnych zajęciach):\n",
        "activation_layers = {\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU(negative_slope=0.1),\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ELU': nn.ELU(alpha=1.0),\n",
        "    'SELU': nn.SELU(),\n",
        "    'Softmax': nn.Softmax(dim=1),\n",
        "    'LogSoftmax': nn.LogSoftmax(dim=1)\n",
        "}\n",
        "\n",
        "# b) Jako funkcje (przydatne w obliczeniach doraźnych):\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Dane wejściowe:\")\n",
        "print(x)\n",
        "\n",
        "print(\"\\nRóżne funkcje aktywacji:\")\n",
        "print(\"ReLU:\", F.relu(x))\n",
        "print(\"Sigmoid:\", torch.sigmoid(x))\n",
        "print(\"Tanh:\", torch.tanh(x))\n",
        "print(\"Softmax:\", F.softmax(x, dim=1))\n",
        "\n",
        "# 2. Funkcje straty (loss functions)\n",
        "loss_functions = {\n",
        "    'MSE': nn.MSELoss(),  # Mean Squared Error - regresja\n",
        "    'BCE': nn.BCELoss(),  # Binary Cross Entropy - klasyfikacja binarna\n",
        "    'CrossEntropy': nn.CrossEntropyLoss(),  # klasyfikacja wieloklasowa\n",
        "    'L1': nn.L1Loss(),  # Mean Absolute Error\n",
        "    'Huber': nn.HuberLoss(),  # połączenie MSE i L1\n",
        "    'KLDiv': nn.KLDivLoss(),  # Kullback-Leibler Divergence\n",
        "}\n",
        "\n",
        "# Przykład użycia funkcji straty:\n",
        "# Regresja\n",
        "x = torch.randn(3, 1)  # predykcje\n",
        "y = torch.randn(3, 1)  # wartości rzeczywiste\n",
        "mse_loss = nn.MSELoss()(x, y)\n",
        "print(f\"\\nMSE Loss: {mse_loss.item()}\")\n",
        "\n",
        "# Klasyfikacja\n",
        "predictions = torch.randn(3, 5)  # logity dla 5 klas\n",
        "targets = torch.tensor([1, 0, 4])  # prawidłowe klasy\n",
        "ce_loss = nn.CrossEntropyLoss()(predictions, targets)\n",
        "print(f\"Cross Entropy Loss: {ce_loss.item()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dane wejściowe:\n",
            "tensor([[-2.2217, -0.4413,  1.8842],\n",
            "        [-0.1960, -1.0472,  0.8071]])\n",
            "\n",
            "Różne funkcje aktywacji:\n",
            "ReLU: tensor([[0.0000, 0.0000, 1.8842],\n",
            "        [0.0000, 0.0000, 0.8071]])\n",
            "Sigmoid: tensor([[0.0978, 0.3914, 0.8681],\n",
            "        [0.4512, 0.2598, 0.6915]])\n",
            "Tanh: tensor([[-0.9768, -0.4147,  0.9549],\n",
            "        [-0.1935, -0.7807,  0.6680]])\n",
            "Softmax: tensor([[0.0148, 0.0877, 0.8975],\n",
            "        [0.2408, 0.1028, 0.6565]])\n",
            "\n",
            "MSE Loss: 4.524075984954834\n",
            "Cross Entropy Loss: 1.3191040754318237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxSdsMUWD9ci"
      },
      "source": [
        "## Kompilacja grafów obliczeniowych\n",
        "\n",
        "W PyTorch również istnieje możliwość optymalizacji kodu poprzez kompilację grafów obliczeniowych, używając torch.jit (znanego jako TorchScript) oraz torch.compile() (wprowadzonego w PyTorch 2.0). Zaletą ich używania jest to, że pozwalają one używać podzbioru normalnego Pythona."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ets0mmTSUVsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cedaaf33-9c41-4ede-e76a-589e9ae9ac7c"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# 1. Używając TorchScript (@torch.jit.script)\n",
        "@torch.jit.script\n",
        "def scripted_fn(x, y):\n",
        "    for i in range(100):\n",
        "        x = x + y\n",
        "    return x\n",
        "\n",
        "# 2. Używając torch.compile (PyTorch 2.0+)\n",
        "@torch.compile\n",
        "def compiled_fn(x, y):\n",
        "    for i in range(100):\n",
        "        x = x + y\n",
        "    return x\n",
        "\n",
        "# 3. Zwykła funkcja Pythona dla porównania\n",
        "def regular_fn(x, y):\n",
        "    for i in range(100):\n",
        "        x = x + y\n",
        "    return x\n",
        "\n",
        "# Przygotowanie danych\n",
        "x = torch.randn(1000, 1000)\n",
        "y = torch.randn(1000, 1000)\n",
        "\n",
        "# Porównanie wydajności\n",
        "def benchmark(fn, name, x, y, warmup=1, runs=5):\n",
        "    # Warmup\n",
        "    for _ in range(warmup):\n",
        "        _ = fn(x, y)\n",
        "\n",
        "    # Pomiar czasu\n",
        "    start = time.time()\n",
        "    for _ in range(runs):\n",
        "        _ = fn(x, y)\n",
        "    end = time.time()\n",
        "\n",
        "    print(f\"{name}: {(end-start)/runs:.4f} sekund na iterację\")\n",
        "\n",
        "# Uruchamiamy benchmark\n",
        "print(\"Porównanie wydajności:\")\n",
        "benchmark(regular_fn, \"Zwykła funkcja\", x, y)\n",
        "benchmark(scripted_fn, \"TorchScript\", x, y)\n",
        "benchmark(compiled_fn, \"Torch Compile\", x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porównanie wydajności:\n",
            "Zwykła funkcja: 0.1193 sekund na iterację\n",
            "TorchScript: 0.1151 sekund na iterację\n",
            "Torch Compile: 0.0056 sekund na iterację\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ważne uwagi:\n",
        "\n",
        "TorchScript (`@torch.jit.script`):\n",
        "\n",
        "- Kompiluje (szybko) kod Python do pośredniej reprezentacji\n",
        "- Pozwala na eksport modelu do formatu niezależnego od Pythona\n",
        "- Ma pewne ograniczenia składniowe i typowanie\n",
        "- Dobry do produkcyjnego wdrażania modeli\n",
        "\n",
        "\n",
        "Torch Compile (`@torch.compile`):\n",
        "\n",
        "- Nowsza metoda wprowadzona w PyTorch 2.0\n",
        "- Często daje lepszą optymalizację\n",
        "- Łatwiejsza w użyciu niż TorchScript\n",
        "- Zachowuje więcej funkcjonalności Pythona\n",
        "- Wymaga dłuższej kompilacji przy pierwszym uruchomienu funkcji.\n",
        "\n",
        "Generalnie od wersji 2.0 zaleca się używanie Torch Compile.\n",
        "Zarówno TorchScript jak i Torch Compile utrudniają debugowanie."
      ],
      "metadata": {
        "id": "v3VHiaonmtuR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ-XK5nUEUWd"
      },
      "source": [
        "## Algorytm wstecznej propagacji błędu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWWYxKRmguWl"
      },
      "source": [
        "Do wyprowadzenia wzorów na aktualizację zmiennych w algorytmie niezbędna jest znajomość zagadnień **chain-rule** oraz **multivariable chain-rule**. Poza podstawową wiedzą z matematyki są to jedyne niezbędne zagadnienia.\n",
        "\n",
        "### Chain-rule & Multivariable Chain-rule\n",
        "\n",
        "Poniżej zostały zaprezentowane zagadnienia **chain-rule** oraz **multivariable chain-rule** w sposób intuicyjny (i graficzny). Poniższa notacja została zaczerpnięta z sieci neuronowych, aby skojarzyć związek z algorytmem **backpropagation**.\n",
        "\n",
        "#### Chain-rule\n",
        "\n",
        "Jest to reguła opierająca się na pochodnej funkcji złożonej. W graficzny sposób można to pokazać następująco:\n",
        "\n",
        "![chain-rule](https://drive.google.com/uc?id=1S8pSUrrOzoisKr8d8YJaQHNLYgEq2dpk)\n",
        "\n",
        "Gdzie $L$ to pewna funkcja dla której liczymy pochodną względem zmiennej $w$. Jak widać, $L$ zależy od $y$, który zależy od $z$ który dopiero zależy bezpośrednio od $w$. Zależności tworzą łańcuch, skąd pochodzi nazwa **chain-rule**.\n",
        "\n",
        "#### Multivariable Chain-rule\n",
        "\n",
        "W przypadku gdy \"łańcuch\" w pewnym momencie się rozgałęzia, dalej możemy korzystać z zasady **chain-rule**, jednak tym razem przybiera ona formę nieco inną (lecz dalej intuicyjną):\n",
        "\n",
        "![multivariable-chain-rule](https://drive.google.com/uc?id=13WH6JXd_5rnTkyToKrBcCZDPdUXCqoT8)\n",
        "\n",
        "W tym przypadku, pochodna funkcji $L$ po zmiennej $z$ wyrażona jest jako suma pochodnych funkcji złożonych odpowiednio $y_1$ oraz $y_2$. Nic nie stoi na przeszkodzie, żeby stosować tę regułę także w sytuacji większej liczby rozgałęzień niż dwa, po prostu zawsze się dodaje pochodne z osobnych \"ścieżek\".\n",
        "\n",
        "<!-- \\\\ %ib: chyba nie jest to tak dobry przykład, jak myślałem...\n",
        "\n",
        "##### **Przykład:**\n",
        "Załóżmy, że mamy funkcję $f(x) = x\\cdot ln(x)$. Możemy ją przedstawić jako $f(x) = g(x)\\cdot h(x)$, gdzie $g(x)=x$ i $h(x)=ln(x)$. Korzystając z multivariable chain-rule możemy wyprowadzić:\n",
        "\n",
        "$$\\frac{\\partial f(x)}{\\partial x} = \\frac{\\partial g(x)h(x)}{\\partial x} = \\frac{\\partial g(x)h(x)}{\\partial g(x)} \\frac{\\partial g(x)}{\\partial x} + \\frac{\\partial g(x)h(x)}{\\partial h(x)} \\frac{\\partial h(x)}{\\partial x} = h(x)\\cdot 1 + g(x)\\cdot \\frac{1}{x} = ln(x) + 1$$\n",
        "\n",
        "Zwróć uwagę, że wzór na pochodną iloczynu jest szczególnym przypadkiem multivariable chain-rule:\n",
        "$$(g(x)h(x))' = g'(x)h(x) + g(x)h'(x) = 1\\cdot ln(x) + x\\cdot\\frac{1}{x} = ln(x) + 1$$ -->\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Backpropagation\n",
        "\n",
        "Algorytm **wstecznej propagacji błędu** jest właściwie jedynie rozwinięciem **reguły delta/uczenia za pomocą metody spadku wzdłóż gradientu**, która została przedstawiona na pierwszych zajęciach. Podobnie jak poprzednio, uczenie neuronów opisane jest w następujący sposób:\n",
        "\n",
        "$$w_i' = w_i - \\mu \\frac{\\partial L}{\\partial w_i} $$\n",
        "\n",
        "Jedyną różnicą jest sposób w jaki się wylicza gradient. Nawiązując do powyższych, krótkich wyjaśnień **chain-rule**, w podobny sposób należy traktować sieci neuronowe.\n",
        "\n",
        "**Dla warstwy wyjściowej** gradient można przedstawić następująco:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_{ij}} = \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial w_{ji}} = \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial z_j}\\frac{\\partial z_j}{\\partial w_{ji}}$$\n",
        "\n",
        "Albo inaczej:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_{ij}} = \\delta_j o_i$$\n",
        "\n",
        "gdzie $w_{ji}$ oznacza wagę połączenia pomiędzy neuronem $j$ a $i$, $\\delta_j = \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial z_j}$ oraz $o_i$ to wyjście z neuronu $i$ (dla neuronów w pierwszej warstwie będą to wejścia do sieci, natomiast w kolejnych warstwach będą to wyjścia z neuronów poprzednich).\n",
        "\n",
        "**Dla warstwy ukrytej** sprawa nieco bardziej się komplikuje. Weźmy jako przykład następującą prostą sieć z 2 warstwami i łącznie 3 neuronami:\n",
        "\n",
        "![simplenet](https://drive.google.com/uc?id=1NXHjEWUX3gAbn8NnHh9eGWdQaSNDavKW)\n",
        "\n",
        "Dla warstwy wyjściowej możemy skorzystać jedynie z **chain-rule** uzyskując następujące równanie:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{2}_{i}} = \\frac{\\partial L}{\\partial y^{2}_i} \\frac{\\partial y^{2}_i}{\\partial z^{2}_i}\\frac{\\partial z^{2}_i}{\\partial w^{2}_{i}} = \\delta^2_i y^1_1$$\n",
        "\n",
        "Przy obliczaniu gradientu dla warstwy ukrytej najpierw stosujemy  proste **chain-rule**:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{1}_{1}} = \\frac{\\partial L}{\\partial y^{1}_1} \\frac{\\partial y^{1}_1}{\\partial z^{1}_1}\\frac{\\partial z^{1}_1}{\\partial w^{1}_{1}}$$\n",
        "\n",
        "W tym momencie można zauważyć, że jest możliwe zastosowanie **multivariable chain-rule** do wyrażenia $\\frac{\\partial L}{\\partial y^{1}_1}$ (ponieważ $L$ nie zależy bezpośrednio od $y^{1}_1$, oraz występuje \"rozgałęzienie\" od $y$):\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial y^{1}_1} = \\frac{\\partial L}{\\partial y^{2}_1} \\frac{\\partial y^{2}_1}{\\partial y^{1}_1} + \\frac{\\partial L}{\\partial y^{2}_2} \\frac{\\partial y^{2}_2}{\\partial y^{1}_1} = \\frac{\\partial L}{\\partial y^{2}_1} \\frac{\\partial y^{2}_1}{\\partial z^{2}_1}\\frac{\\partial z^{2}_1}{\\partial y^{1}_1} + \\frac{\\partial L}{\\partial y^{2}_2} \\frac{\\partial y^{2}_2}{\\partial z^{2}_2} \\frac{\\partial z^{2}_2}{\\partial y^{1}_1}$$\n",
        "\n",
        "Tu można zauważyć, że $\\frac{\\partial z^{2}_2}{\\partial y^{1}_1} = w^2_2$ oraz $\\frac{\\partial L}{\\partial y^{2}_2} \\frac{\\partial y^{2}_2}{\\partial z^{2}_2} = \\delta^2_2$ (przy założeniu liniowej funkcji aktywacji), co daje nam końcowo:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial y^{1}_1} = \\sum_i^2 \\delta^2_i w^2_i$$\n",
        "\n",
        "Podstawiając do wcześniejszego wzoru otrzymujemy:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{1}_{1}} = \\sum_i^2 \\delta^2_i w^2_i \\frac{\\partial y^{1}_1}{\\partial z^{1}_1}\\frac{\\partial z^{1}_1}{\\partial w^{1}_{1}}$$\n",
        "\n",
        "Ostatecznie, za pomocą następujących podstawień możemy sprowadzić powyższe równanie do wersji spójnej z gradientem dla warstwy wyjściowej:\n",
        "\n",
        "$$\\sum_i^2 \\delta^2_i w^2_i \\frac{\\partial y^{1}_1}{\\partial z^{1}_1} = \\delta^1_1$$\n",
        "$$\\frac{\\partial z^{1}_1}{\\partial w^{1}_{1}} = x$$\n",
        "$$\\frac{\\partial L}{\\partial w^{1}_{1}} = \\delta^1_1 x$$\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Podsumowując, zarówno dla warstwy wyjściowej jak i warstwy ukrytej gradienty możemy przedstawić w tej samej formie, składającej się z **błędu neuronu** ($\\delta$), oraz wyjścia z poprzedniej warstwy ($y$ lub $x$).\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{i}_{j}} = \\delta^i_j o^{(i-1)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKj35Ykeqzn"
      },
      "source": [
        "### Automatyczna wsteczna propagacja błędu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3PfOaWcE9q"
      },
      "source": [
        "Można rozpatrywać różne algorytmy optymalizacji działające na bazie algorytmu wstecznej propagacji błędu, który sam w sobie jest po prostu pewną strategią przydziału informacji o błędzie do zmiennych, a to jak na tej podstawie będziemy je modyfikować pozostaje otwartą kwestią. Jednym z prostszych optymalizatorów jest **Stochastic Gradient Descent** (SGD). Różni się od klasycznego Gradient Descent tym, że w jego przypadku gradient liczony jest w każdej iteracji dla losowo wybranego podzbioru danych uczących zamiast dla wszystkich. Innym popularnym optymalizatorem jest **ADAM** (od \"adaptive moment estimation\"), który każdą zmienną modyfikuje na podstawie jej statystycznych momentów (rzędu 1 i 2) gradientu w pewnym oknie czasowym. Ogólnie konstruowanie optymalizatorów opartych na gradiencie to cała osobna obszerna dziedzina naukowa. Przykładowo, na niektórych problemach ADAM ma znacznie szybszą zbieżność niż SGD, ale na innych zauważalnie gorzej radzi sobie z uogólnieniem wiedzy i w efekcie błąd na zbiorze testowym jest większy.\n",
        "\n",
        "Poniżej zaprezentowany został algorytm wstecznej propagacji błędu zaimplementowany w bibliotece PyTorch. Przykład składa się z definicji sieci neuronowej, funkcji straty oraz jednego kroku uczenia przy użyciu gotowego optymalizatora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyUufSiJEgUH"
      },
      "source": [
        "### Prosta sieć neuronowa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra9SuKPAE1wU"
      },
      "source": [
        "import torch\n",
        "\n",
        "# zmienne uczone pojedynczego neuronu, który na wejście otrzymuje wektor 10 liczb\n",
        "w = torch.nn.Parameter(torch.ones(10, 1))\n",
        "b = torch.nn.Parameter(torch.ones(1))\n",
        "\n",
        "# definicja 1-warstwowej sieci neuronowej z funkcją aktywacji relu\n",
        "# (@ jest również aliasem do torch.matmul() w PyTorch)\n",
        "def network(x):\n",
        "    return torch.relu(x @ w + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c97P9HzdEnID"
      },
      "source": [
        "### Funkcja straty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAaD7jSpyUmk"
      },
      "source": [
        "W poniższym kodzie torch.mean to odpowiednik np.mean i działa tak samo. Jako drugi argument można podać wymiar, po którym liczona będzie średnia (domyślnie liczona jest z wszystkich wymiarów). Jeżeli chodzi o *reduce* (nazywane również *fold*) w nazwie, to jest to schemat obliczeń często wykorzystywany w paradygmacie programowania funkcyjnego, i polega na rekurencyjnym przechodzeniu przez strukturę przy jednoczesnym konstruowaniu nowej, w pewnym sensie redukując tę strukturę (np. macierz liczb) do nowej struktury (np. liczby)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqwbPkFiE2UZ"
      },
      "source": [
        "# mean squared error jako funkcja straty\n",
        "def loss_fn(y_pred, y_true):\n",
        "   return torch.mean((y_pred - y_true) ** 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWv0Fg36Epug"
      },
      "source": [
        "### Obliczenie gradientu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ejn6iHQE2kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b2c5a6-12c8-4df4-9eff-8943cd8796e5"
      },
      "source": [
        "# wsteczna propagacja błędu obsługiwana jest przez optymalizatory dostępne w PyTorch\n",
        "optimizer = torch.optim.Adam([w, b], lr=0.001)\n",
        "#optimizer = torch.optim.SGD([w, b], lr=0.001)  # a tutaj Stochastic Gradient Descent\n",
        "\n",
        "# wejście oraz pożądane wyjście z sieci neuronowej\n",
        "x = torch.rand(32, 10)\n",
        "y_true = torch.ones(32, 1)\n",
        "\n",
        "# W PyTorch nie potrzebujemy GradientTape, gradienty są obliczane automatycznie\n",
        "# Najpierw zerujemy gradienty z poprzedniej iteracji\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass\n",
        "y_pred = network(x)\n",
        "l = loss_fn(y_pred, y_true)\n",
        "\n",
        "# Backward pass - obliczenie gradientów\n",
        "l.backward()\n",
        "\n",
        "# Aktualizacja parametrów przez optymalizator\n",
        "optimizer.step()\n",
        "\n",
        "# Wyświetlenie gradientów\n",
        "print([w.grad, b.grad])  # gradienty są przechowywane w .grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[5.5295],\n",
            "        [4.7832],\n",
            "        [4.8561],\n",
            "        [5.4669],\n",
            "        [4.4064],\n",
            "        [5.3732],\n",
            "        [4.9433],\n",
            "        [5.8479],\n",
            "        [5.4676],\n",
            "        [4.3909]]), tensor([9.9962])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idPo7uRZexv9"
      },
      "source": [
        "#### Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFKkCPhgezMI"
      },
      "source": [
        "Korzystając z wiedzy z tych i poprzednich zajęć stwórz sieć neuronową składającą się z 3 warstw o rozmiarach odpowiednio 1, 2, 1. Niech w pierwszej i drugiej warstwie funkcją aktywacji będzie sigmoid a wyjście z sieci funkcją liniową. Skorzystaj z funkcji straty MSE.\n",
        "\n",
        "Naucz sieć neuronową, aby wykonywała funkcję **sinus** (wejściem sieci niech będzie kąt wyrażony w radianach). Trening sieci powinien polegać na wykonaniu algorytmu wstecznej propagacji błędu **ITERS** razy. Każda iteracja niech przetwarza **batch** danych o rozmiarze 16. Do nauki sieci wykorzystaj algorytm **Stochastic Gradient Descent** (`torch.optim.SGD`).\n",
        "\n",
        "W celu optymalizacji szybkości działania, dodaj do definicji modelu adnotację @torch.compile.\n",
        "\n",
        "Przy domyślnych parametrach wyjdzie zasadniczo linia prosta na zerze. Poeksperymentuj z prędkością uczenia i liczbą iteracji, by poprawić ten rezultat. Sprawdź, jak działa ReLU dla tego problemu. Dla sigmoidalnej funkcji aktywacji rezultat powinien przypominać następujący wykres:\n",
        "\n",
        "![alt text](https://www.cs.put.poznan.pl/ibladek/students/eio/img/expected_sine.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ITERS = 10000  # ilość iteracji\n",
        "LR = 0.01  # prędkość uczenia\n",
        "\n",
        "# pierwsza warstwa\n",
        "w1 = torch.nn.Parameter(torch.rand(1, 2))\n",
        "b1 = torch.nn.Parameter(torch.rand(2))\n",
        "\n",
        "# druga warstwa\n",
        "w2 = torch.nn.Parameter(torch.rand(2, 2))\n",
        "b2 = torch.nn.Parameter(torch.rand(2))\n",
        "\n",
        "# trzecia warstwa\n",
        "w3 = torch.nn.Parameter(torch.rand(2, 1))\n",
        "b3 = torch.nn.Parameter(torch.rand(1))\n",
        "\n",
        "def layer_1(x):\n",
        "    ...\n",
        "\n",
        "def layer_2(x):\n",
        "    ...\n",
        "\n",
        "def layer_3(x):\n",
        "    ...\n",
        "\n",
        "def network(x):  # obliczanie wyjścia sieci\n",
        "    ...\n",
        "\n",
        "all_parameters = [w1, b1, w2, b2, w3, b3]\n",
        "optimizer = torch.optim.SGD(all_parameters, lr=LR)\n",
        "\n",
        "for i in range(ITERS):\n",
        "    # dane wejściowe\n",
        "    x = torch.rand(16, 1) * (2 * math.pi)\n",
        "    y_true = torch.sin(x)  # dane uczące (ground truth)\n",
        "    x = (x - math.pi) / (2 * math.pi) # przeskalowanie danych do [-1, 1]\n",
        "\n",
        "    # zerowanie gradientów\n",
        "    ...\n",
        "\n",
        "    # forward pass\n",
        "    ...\n",
        "\n",
        "    # obliczanie błędu\n",
        "    ...\n",
        "\n",
        "    # backward pass\n",
        "    ...\n",
        "\n",
        "    # aktualizacja wag\n",
        "    ...\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f'Iteracja {i}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# testowanie sieci na zbiorze testowym\n",
        "x = torch.linspace(0, 2 * math.pi, 100).reshape(-1, 1)\n",
        "y_test = torch.sin(x)\n",
        "x = (x - math.pi) / (2 * math.pi)\n",
        "with torch.no_grad():  # wyłączamy obliczanie gradientów podczas testowania\n",
        "    y_pred = network(x)\n",
        "\n",
        "# konwersja do numpy dla matplotlib\n",
        "x = x.numpy()\n",
        "y_test = y_test.numpy()\n",
        "y_pred = y_pred.numpy()\n",
        "\n",
        "plt.plot(x, y_test, label='sin(x)')\n",
        "plt.plot(x, y_pred, label='network(x)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-yoSVpH5pVvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rePvYrKH51OD"
      },
      "source": [
        "#### Zadanie 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_yWbmVHhCWj"
      },
      "source": [
        "Wykonaj ponownie zadanie 2, tym razem samodzielnie implementując algorytm backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfcJ-fiiiK0i"
      },
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ITERS = 10000  # ilość iteracji\n",
        "LR = 0.01  # prędkość uczenia\n",
        "\n",
        "# pierwsza warstwa\n",
        "w1 = torch.rand(1, 2, requires_grad=True)\n",
        "b1 = torch.rand(2, requires_grad=True)\n",
        "\n",
        "# druga warstwa\n",
        "w2 = torch.rand(2, 2, requires_grad=True)\n",
        "b2 = torch.rand(2, requires_grad=True)\n",
        "\n",
        "# trzecia warstwa\n",
        "w3 = torch.rand(2, 1, requires_grad=True)\n",
        "b3 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "def layer_1(x):\n",
        "    ...\n",
        "\n",
        "def layer_2(x):\n",
        "    ...\n",
        "\n",
        "def layer_3(x):\n",
        "    ...\n",
        "\n",
        "def network(x):  # obliczanie wyjścia sieci\n",
        "    ...\n",
        "\n",
        "\n",
        "\n",
        "for i in range(ITERS):\n",
        "    # dane wejściowe\n",
        "    x = torch.rand(16, 1) * (2 * math.pi)\n",
        "    y_true = torch.sin(x)  # dane uczące (ground truth)\n",
        "    x = (x - math.pi) / (2 * math.pi) # przeskaluj dane do [-1, 1]\n",
        "\n",
        "    ...\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f'Iteracja {i}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# testowanie sieci na zbiorze testowym\n",
        "x = torch.linspace(0, 2 * math.pi, 100).reshape(-1, 1)\n",
        "y_test = torch.sin(x)\n",
        "x = (x - math.pi) / (2 * math.pi)\n",
        "with torch.no_grad():  # wyłączamy obliczanie gradientów podczas testowania\n",
        "    y_pred = network(x)\n",
        "\n",
        "# konwersja do numpy dla matplotlib\n",
        "x = x.numpy()\n",
        "y_test = y_test.numpy()\n",
        "y_pred = y_pred.numpy()\n",
        "\n",
        "plt.plot(x, y_test, label='sin(x)')\n",
        "plt.plot(x, y_pred, label='network(x)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}